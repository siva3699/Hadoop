



val ordersmap = sc.textFile("file:///root/retail_db/orders").map( rec => ( rec.split(",")(0),rec.split(",")(1)))

org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[14] at map at <console>:27

output:- 

(68878,2014-07-08 00:00:00.0)
(68879,2014-07-09 00:00:00.0)
(68880,2014-07-13 00:00:00.0)
(68881,2014-07-19 00:00:00.0)
(68882,2014-07-22 00:00:00.0)
(68883,2014-07-23 00:00:00.0)


val new_orders = ordersmap.map( rec => "%s,%s".format(rec._1,rec._2))

org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[18] at map at <console>:29


output:-

68875,2014-07-04 00:00:00.0
68876,2014-07-06 00:00:00.0
68877,2014-07-07 00:00:00.0
68878,2014-07-08 00:00:00.0
68879,2014-07-09 00:00:00.0
68880,2014-07-13 00:00:00.0
68881,2014-07-19 00:00:00.0
68882,2014-07-22 00:00:00.0
68883,2014-07-23 00:00:00.0
